| module                    | #parameters or shape   | #flops     |
|:--------------------------|:-----------------------|:-----------|
| model                     | 0.574M                 | 0.132G     |
|  S_layer                  |  1.025K                |  0.611M    |
|   S_layer.layer_scale_1   |   (32,)                |            |
|   S_layer.layer_scale_2   |   (32,)                |            |
|   S_layer.norm            |   0.48K                |   57.6K    |
|    S_layer.norm.weight    |    (1, 12, 20)         |            |
|    S_layer.norm.bias      |    (1, 12, 20)         |            |
|   S_layer.layer           |   0.384K               |   0.184M   |
|    S_layer.layer.0        |    64                  |    0.184M  |
|    S_layer.layer.1        |    0.32K               |    0       |
|   S_layer.att.0           |   64                   |   0.184M   |
|    S_layer.att.0.weight   |    (32, 1, 1, 1)       |            |
|    S_layer.att.0.bias     |    (32,)               |            |
|   S_layer.final           |   33                   |   0.184M   |
|    S_layer.final.weight   |    (1, 32, 1, 1)       |            |
|    S_layer.final.bias     |    (1,)                |            |
|  T_layer                  |  0.573M                |  0.132G    |
|   T_layer.layer_scale_1   |   (512,)               |            |
|   T_layer.layer_scale_2   |   (512,)               |            |
|   T_layer.norm            |   11.52K               |   28.8K    |
|    T_layer.norm.weight    |    (24, 12, 20)        |            |
|    T_layer.norm.bias      |    (24, 12, 20)        |            |
|   T_layer.initial         |   12.8K                |   2.949M   |
|    T_layer.initial.weight |    (512, 24, 1, 1)     |            |
|    T_layer.initial.bias   |    (512,)              |            |
|   T_layer.statical        |   0.273M               |   62.915M  |
|    T_layer.statical.0     |    5.12K               |    0       |
|    T_layer.statical.1     |    5.12K               |    0       |
|    T_layer.statical.2     |    0.263M              |    62.915M |
|   T_layer.dynamical       |   0.263M               |   63.037M  |
|    T_layer.dynamical.1    |    0.263M              |    62.915M |
|    T_layer.dynamical.0    |                        |    0.123M  |
|   T_layer.final           |   12.312K              |   2.949M   |
|    T_layer.final.weight   |    (24, 512, 1, 1)     |            |
|    T_layer.final.bias     |    (24,)               |            |
|  final                    |                        |  5.76K     |
Epoch 1 | Loss : 1.436908 | Time : 4.0009
Epoch 1 | Val Loss : 1.353586 | Time : 0.3608
Best model saved with loss 1.353586 at epoch 1
Epoch 2 | Loss : 1.424827 | Time : 2.8548
Epoch 2 | Val Loss : 1.342326 | Time : 0.3567
Best model saved with loss 1.342326 at epoch 2
Epoch 3 | Loss : 1.081516 | Time : 2.8489
Epoch 3 | Val Loss : 0.910362 | Time : 0.3565
Best model saved with loss 0.910362 at epoch 3
Epoch 4 | Loss : 0.830085 | Time : 2.8487
Epoch 4 | Val Loss : 0.703236 | Time : 0.3558
Best model saved with loss 0.703236 at epoch 4
Epoch 5 | Loss : 0.726790 | Time : 2.8436
Epoch 5 | Val Loss : 0.653245 | Time : 0.3564
Best model saved with loss 0.653245 at epoch 5
Epoch 6 | Loss : 0.661697 | Time : 2.8493
Epoch 6 | Val Loss : 0.564183 | Time : 0.3557
Best model saved with loss 0.564183 at epoch 6
Epoch 7 | Loss : 0.603921 | Time : 2.8506
Epoch 7 | Val Loss : 0.518226 | Time : 0.3559
Best model saved with loss 0.518226 at epoch 7
Epoch 8 | Loss : 0.565374 | Time : 2.8541
Epoch 8 | Val Loss : 0.502989 | Time : 0.3563
Best model saved with loss 0.502989 at epoch 8
Epoch 9 | Loss : 0.543445 | Time : 2.8553
Epoch 9 | Val Loss : 0.493781 | Time : 0.3574
Best model saved with loss 0.493781 at epoch 9
Epoch 10 | Loss : 0.529396 | Time : 2.8531
Epoch 10 | Val Loss : 0.490943 | Time : 0.3573
Best model saved with loss 0.490943 at epoch 10
Epoch 11 | Loss : 0.521338 | Time : 2.8559
Epoch 11 | Val Loss : 0.472201 | Time : 0.3570
Best model saved with loss 0.472201 at epoch 11
Epoch 12 | Loss : 0.514018 | Time : 2.8553
Epoch 12 | Val Loss : 0.466281 | Time : 0.3567
Best model saved with loss 0.466281 at epoch 12
Epoch 13 | Loss : 0.505946 | Time : 2.8504
Epoch 13 | Val Loss : 0.463940 | Time : 0.3565
Best model saved with loss 0.463940 at epoch 13
Epoch 14 | Loss : 0.502198 | Time : 2.8493
Epoch 14 | Val Loss : 0.466691 | Time : 0.3569
Epoch 15 | Loss : 0.497396 | Time : 2.8499
Epoch 15 | Val Loss : 0.471103 | Time : 0.3554
Epoch 16 | Loss : 0.490535 | Time : 2.8474
Epoch 16 | Val Loss : 0.460863 | Time : 0.3559
Best model saved with loss 0.460863 at epoch 16
Epoch 17 | Loss : 0.488744 | Time : 2.8531
Epoch 17 | Val Loss : 0.454621 | Time : 0.3573
Best model saved with loss 0.454621 at epoch 17
Epoch 18 | Loss : 0.483082 | Time : 2.8531
Epoch 18 | Val Loss : 0.466881 | Time : 0.3570
Epoch 19 | Loss : 0.481275 | Time : 2.8506
Epoch 19 | Val Loss : 0.452402 | Time : 0.3572
Best model saved with loss 0.452402 at epoch 19
Epoch 20 | Loss : 0.476848 | Time : 2.8531
Epoch 20 | Val Loss : 0.450351 | Time : 0.3560
Best model saved with loss 0.450351 at epoch 20
Epoch 21 | Loss : 0.476892 | Time : 2.8526
Epoch 21 | Val Loss : 0.450669 | Time : 0.3568
Epoch 22 | Loss : 0.472587 | Time : 2.8481
Epoch 22 | Val Loss : 0.449885 | Time : 0.3553
Best model saved with loss 0.449885 at epoch 22
Epoch 23 | Loss : 0.469704 | Time : 2.8536
Epoch 23 | Val Loss : 0.455274 | Time : 0.3549
Epoch 24 | Loss : 0.468501 | Time : 2.8497
Epoch 24 | Val Loss : 0.445083 | Time : 0.3561
Best model saved with loss 0.445083 at epoch 24
Epoch 25 | Loss : 0.467932 | Time : 2.8539
Epoch 25 | Val Loss : 0.450169 | Time : 0.3569
Epoch 26 | Loss : 0.465747 | Time : 2.8473
Epoch 26 | Val Loss : 0.461816 | Time : 0.3568
Epoch 27 | Loss : 0.463394 | Time : 2.8487
Epoch 27 | Val Loss : 0.447615 | Time : 0.3566
Epoch 28 | Loss : 0.461836 | Time : 2.8492
Epoch 28 | Val Loss : 0.452112 | Time : 0.3558
Epoch 29 | Loss : 0.460318 | Time : 2.8475
Epoch 29 | Val Loss : 0.449295 | Time : 0.3561
Epoch 30 | Loss : 0.459995 | Time : 2.8501
Epoch 30 | Val Loss : 0.444833 | Time : 0.3558
Best model saved with loss 0.444833 at epoch 30
Epoch 31 | Loss : 0.457164 | Time : 2.8530
Epoch 31 | Val Loss : 0.448382 | Time : 0.3567
Epoch 32 | Loss : 0.456568 | Time : 2.8486
Epoch 32 | Val Loss : 0.439101 | Time : 0.3575
Best model saved with loss 0.439101 at epoch 32
Epoch 33 | Loss : 0.454537 | Time : 2.8502
Epoch 33 | Val Loss : 0.446347 | Time : 0.3558
Epoch 34 | Loss : 0.453176 | Time : 2.8467
Epoch 34 | Val Loss : 0.442237 | Time : 0.3593
Epoch 35 | Loss : 0.452665 | Time : 2.8463
Epoch 35 | Val Loss : 0.445118 | Time : 0.3569
Epoch 36 | Loss : 0.450502 | Time : 2.8438
Epoch 36 | Val Loss : 0.442002 | Time : 0.3548
Epoch 37 | Loss : 0.450312 | Time : 2.8479
Epoch 37 | Val Loss : 0.442644 | Time : 0.3563
Epoch 38 | Loss : 0.449567 | Time : 2.8426
Epoch 38 | Val Loss : 0.439200 | Time : 0.3555
Epoch 39 | Loss : 0.449053 | Time : 2.8472
Epoch 39 | Val Loss : 0.439580 | Time : 0.3557
Epoch 40 | Loss : 0.449742 | Time : 2.8444
Epoch 40 | Val Loss : 0.438814 | Time : 0.3558
Best model saved with loss 0.438814 at epoch 40
Epoch 41 | Loss : 0.448681 | Time : 2.8508
Epoch 41 | Val Loss : 0.440573 | Time : 0.3571
Epoch 42 | Loss : 0.448449 | Time : 2.8479
Epoch 42 | Val Loss : 0.438959 | Time : 0.3559
Epoch 43 | Loss : 0.446688 | Time : 2.8449
Epoch 43 | Val Loss : 0.439159 | Time : 0.3555
Epoch 44 | Loss : 0.447189 | Time : 2.8460
Epoch 44 | Val Loss : 0.438542 | Time : 0.3542
Best model saved with loss 0.438542 at epoch 44
Epoch 45 | Loss : 0.447290 | Time : 2.8483
Epoch 45 | Val Loss : 0.440111 | Time : 0.3568
Epoch 46 | Loss : 0.447337 | Time : 2.8456
Epoch 46 | Val Loss : 0.439393 | Time : 0.3554
Epoch 47 | Loss : 0.447199 | Time : 2.8445
Epoch 47 | Val Loss : 0.439088 | Time : 0.3551
Epoch 48 | Loss : 0.446987 | Time : 2.8463
Epoch 48 | Val Loss : 0.439142 | Time : 0.3535
Epoch 49 | Loss : 0.445548 | Time : 2.8488
Epoch 49 | Val Loss : 0.439216 | Time : 0.3563
Epoch 50 | Loss : 0.445828 | Time : 2.8444
Epoch 50 | Val Loss : 0.439316 | Time : 0.3562
Test
MSE : 0.032946 | MAE : 0.109082 | RMSE : 0.168159 | MAPE : 8.685827 | SMAPE : 4.721230
